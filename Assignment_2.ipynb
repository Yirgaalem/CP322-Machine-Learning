{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yirgaalem/CP322-Machine-Learning/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eGA5YxF97E3"
      },
      "source": [
        "\n",
        "# CP 322– Machine Learning – Fall 2022\n",
        "## Assignment 2\n",
        "### Due: Nov 4th, 2022, 11:59 pm\n",
        "\n",
        "Ojective of this assignment:\n",
        "\n",
        "Application of ML in analyzing text documents:\n",
        "\n",
        "In this asssignment, we take advantage of scikit-learn in working with text documents. This will also be an excercise to figure out how to write a code with a new machine learning package; this is a necessary skill in applied machine learning, since the packages evolve quickly (and there are many of them) so being able to figure out how to work with a tool within a reasonble time frame is important. If you need further details you can check out to this <a href=\"https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\" > scikit example </a>, or other scikit documentations.\n",
        "\n",
        "# Procedure:\n",
        "\n",
        "You need to make a copy of this notebook and download the dataset file. Write the answar in the provided space.\n",
        "\n",
        "For submission, you need to upload this notebook in Assignment2 dropbox section.\n",
        "- There are three tasks for you.\n",
        "- Submit your code and justify your results in the same Jupiter notebook format. \n",
        "   (keep the overal format of the notebook unchanged)\n",
        "\n",
        "Rename the submitted file as Assignment2_student_id.\n",
        "\n",
        "Make a copy of this colab so that you can modify it for yourself. If google colab is slow, you can also download the notebook and use Jupyter notebook on your computer. Using the online notebook has the benefit that all the required packages are already installed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRjQi9nP-CdA"
      },
      "source": [
        "# Packages\n",
        "\n",
        "First of all, let's import the packages we need for this assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNRer4Oz-Mxd"
      },
      "outputs": [],
      "source": [
        "# loading need libraries\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQyhj3jX-Oqk"
      },
      "source": [
        "# Dataset characteristics\n",
        "\n",
        "The dataset for this work is available for download from the [Cornell Natural Language Processing Group](https://www.cs.cornell.edu/people/pabo/movie-review-data/). There are a total of 2000 documents in the collection. The favourable ratings are found in half of the documents, while the negative reviews are found in the other half. This site has further information on the dataset. If you are unable to download the dataset for the above link, download the \n",
        "txt_sentoken.zip file of the dataset in the assignment 2 folder, unzip it and change the path in the load_files function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAPTE5Jj-RdK"
      },
      "outputs": [],
      "source": [
        "#!wget http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\n",
        "#!tar xzf review_polarity.tar.gz\n",
        "movie_data = load_files(\"/content/txt_sentoken\") # Change the path according to your PC path.\n",
        "reviews, labels = movie_data.data, movie_data.target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czZDsYDBC7uW",
        "outputId": "53c7df8f-0c17-430a-ec8c-a707887fafae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset properties :\n",
            "\t Number of reviews: 2000\n",
            "\t Number of Classes: 3\n",
            "\t Number of reviews for training set: 1600\n",
            "\t Number of reviews for test set: 400\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset properties :\")\n",
        "print(\"\\t Number of reviews: %d\" % len(reviews))\n",
        "print(\"\\t Number of Classes: %d\" % (max(labels)+1))\n",
        "reviews_train, reviews_test, labels_train, labels_test = train_test_split(reviews, labels, test_size=0.2, random_state=0)\n",
        "print(\"\\t Number of reviews for training set: %d\" % len(reviews_train))\n",
        "print(\"\\t Number of reviews for test set: %d\" % len(reviews_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_zM6QeerbKT"
      },
      "source": [
        "# Text Preprocessing \n",
        "The next step is to preprocess the text after the dataset has been imported.\n",
        "Numbers, special characters, and undesired spaces are all possible in text.\n",
        "We may or may not need to delete certain special letters and numbers from text, depending on the situation. We shall, however, delete any special characters, digits, and unnecessary spaces from our text for the purpose of clarity.\n",
        "To preprocess the data, run the script below: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjcdUke5sBNW",
        "outputId": "2d4d7e61-c3f5-4711-ab70-de816628e801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def text_preprocessing(input):\n",
        "  # Remove all the special characters\n",
        "    document = re.sub(r'\\W', ' ', str(input))\n",
        "    \n",
        "    # remove all single characters\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    \n",
        "    # Remove single characters from the start\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    \n",
        "    # Substituting multiple spaces with single space\n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    \n",
        "    # Removing prefixed 'b'\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    \n",
        "    # Converting to Lowercase\n",
        "    document = document.lower()\n",
        "    \n",
        "    # Lemmatization\n",
        "    document = document.split()\n",
        "\n",
        "    document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    return document\n",
        "stemmer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45KwpFrUvWyv"
      },
      "source": [
        "**Importance of preprocessing:**\n",
        "The following is an example of text preparation in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRjMM7eXu8lL",
        "outputId": "e8da3be2-a051-4b67-f89a-e947ed6204e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before preprocessing: \n",
            " b'it was a rainy friday afternoon in columbus when i persuaded a friend to see a matinee performance of mst3k : tm . \\nhe had never seen any episodes of the show , and i have watched a scant few , due to its unsocial airtime on comedy central and the uneven nature of many of the episodes . \\nfor those of you not familiar with the premise , dr clayton forrester ( beaulieu ) wishes to take over the world by finding the worst film ever made and unleashing it upon an unsuspecting public . \\nto achieve this , he ( in the words of the tv series\\' theme , which is missing in the movie ) \" bumped [mike nelson ( nelson ) ] on the noggin and then shot him into space \" , and is monitoring nelson\\'s reactions to the movies he is forced to endure . \\nrather than succumb to the sheer awfulness of many of the movies , nelson spends his time making wisecracks with the help of his two robot companions , tom servo and crow t . robot . \\nthe format of the show consists of nelson , servo and crow making their comments while silhouetted against the movie being watched , and breaks every 20 minutes or so for segments set on the satellite of love , the ship on which our heroes are marooned . \\nonly two things are different in the movie : the absence of forrester\\'s sidekick , tv\\'s frank , and the slower pace of the jokes . \\nthis latter change is presumably deliberate to avoid the viewing audience missing some of the best lines while laughing from the previous joke . \\nfor their big screen outing , the producers have chosen \" this island earth \" , a 1954 classic , and one of the first sf films to have a special effects budget larger than the average grocery bill . \\nunfortunately for that film ( but making it ideal mst3k fodder ) , acting and dialogue appear to have taken a back seat to the effects which , by today\\'s standards , are less than impressive . \\nnelson & co . make jokes about everything from japan\\'s dominance in the world market , to star trek , to the state of disrepair of seattle\\'s kingdome , and most of them work . \\nunfortunately , the segments set outside the satellite\\'s movie theater seem out of place and aren\\'t particularly funny , but at least they\\'re fairly short . \\nthe big question about this movie though is : why ? \\ni presume it was an attempt to gain a larger following to keep support behind the series ( rumours of its impending demise circulated for some time before the plug was eventually pulled a few months ago ) , but the format gains nothing from its transition to the big screen -- there are no special effects to dazzle you , no action sequences to keep you on the edge of your seat , and no use of digital surround sound . \\nso , it seems pointless to spend $8 per person to see this movie when in a few months it will be out on video and you can watch it for $3 , and not have to sit in a room full of popcorn addicts . \\nnevertheless , mst3k : tm provides more laugh-out-loud opportunities than any film you\\'re going to see this year , and i thoroughly recommend it to anyone with a pulse . \\ngiven its uniqueness , i hesitate to grade it against other films , but it fulfils its claims and so in the class of \" unsubtle comedy films whose laughs come at the expense of bad b-movies \" it does well . \\n'\n"
          ]
        }
      ],
      "source": [
        "print('before preprocessing: \\n',reviews_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuNYcyCPvODO",
        "outputId": "735b0fe7-e1d6-4f3d-d313-72072f6350eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after preprocessing: \n",
            " it wa rainy friday afternoon in columbus when persuaded friend to see matinee performance of mst3k tm nhe had never seen any episode of the show and have watched scant few due to it unsocial airtime on comedy central and the uneven nature of many of the episode nfor those of you not familiar with the premise dr clayton forrester beaulieu wish to take over the world by finding the worst film ever made and unleashing it upon an unsuspecting public nto achieve this he in the word of the tv series theme which is missing in the movie bumped mike nelson nelson on the noggin and then shot him into space and is monitoring nelson reaction to the movie he is forced to endure nrather than succumb to the sheer awfulness of many of the movie nelson spends his time making wisecrack with the help of his two robot companion tom servo and crow robot nthe format of the show consists of nelson servo and crow making their comment while silhouetted against the movie being watched and break every 20 minute or so for segment set on the satellite of love the ship on which our hero are marooned nonly two thing are different in the movie the absence of forrester sidekick tv frank and the slower pace of the joke nthis latter change is presumably deliberate to avoid the viewing audience missing some of the best line while laughing from the previous joke nfor their big screen outing the producer have chosen this island earth 1954 classic and one of the first sf film to have special effect budget larger than the average grocery bill nunfortunately for that film but making it ideal mst3k fodder acting and dialogue appear to have taken back seat to the effect which by today standard are le than impressive nnelson co make joke about everything from japan dominance in the world market to star trek to the state of disrepair of seattle kingdome and most of them work nunfortunately the segment set outside the satellite movie theater seem out of place and aren particularly funny but at least they re fairly short nthe big question about this movie though is why ni presume it wa an attempt to gain larger following to keep support behind the series rumour of it impending demise circulated for some time before the plug wa eventually pulled few month ago but the format gain nothing from it transition to the big screen there are no special effect to dazzle you no action sequence to keep you on the edge of your seat and no use of digital surround sound nso it seems pointless to spend 8 per person to see this movie when in few month it will be out on video and you can watch it for 3 and not have to sit in room full of popcorn addict nnevertheless mst3k tm provides more laugh out loud opportunity than any film you re going to see this year and thoroughly recommend it to anyone with pulse ngiven it uniqueness hesitate to grade it against other film but it fulfils it claim and so in the class of unsubtle comedy film whose laugh come at the expense of bad movie it doe well\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "print('after preprocessing: \\n',text_preprocessing(reviews_train[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYLjG8btNjoH"
      },
      "source": [
        "# Apply pre-processing step on the entire dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2jsuMkkNswd"
      },
      "outputs": [],
      "source": [
        "pre_processed_reviews_train = [text_preprocessing(rev) for rev in reviews_train]\n",
        "pre_processed_reviews_test = [text_preprocessing(rev) for rev in reviews_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9av39ipneTYl"
      },
      "source": [
        "# Feature extraction\n",
        "since our data is text, to run classification models on the dataset we will turn them into vectors with numerical features. Therefore, in this section, we extract features using the **Bag of Words** method. To this regard, \n",
        "\n",
        "\n",
        "*   Assign an integer ID to each word in the dataset (like a dictionary).\n",
        "*   For each data point ( document i), count the number of occurances of word w and put it in X[i,j] where i is the i'th document and j is the index of the word w in the dictionary.\n",
        "Thus, if we have e.g., 10000 data points and 100000 words in the dictionary, then X will be a 10,000 by 100,000 matrix, which is huge! The good news is that most elements of the matrix X are zero (not all the words are used in every document). Therefore, it is possible to (somehow) just store non-zero elements and save up a lot of memory. Fortunately, the library that we use supports using \"sparse\" data representations, meaning that it does not actually store all the zero-values.\n",
        "# Tokenizing with scikit-learn\n",
        "In the following part we extract whole words that have been used in the dataset and compute their occurance count in each document. This shows number of documents are **1600** and number of features (unique words in the whole set of documents) is **36551**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXpFn4Anh-bF",
        "outputId": "87a7e352-7736-4a16-eb75-3025e7618442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 36551)\n"
          ]
        }
      ],
      "source": [
        "count_vect = CountVectorizer()\n",
        "X_counts_train = count_vect.fit_transform(np.array(pre_processed_reviews_train))\n",
        "print(X_counts_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbizhQupjOuo"
      },
      "source": [
        "Up to here, we turned each document into an occurrence feature map (i.e., bag of words representation). But there is an issue with this solution: longer documents tend to have larger occurrence values. This is not ideal; for example, if we just repeat the same text twice, we don't expect the category of that document to change, but the occurance values will drastically change.\n",
        "\n",
        "\n",
        "Solution: we better normalize each document by dividing the occurrence values of each word by the total number of words in the document (*tf* normalization, where tf stands for term-frequency).\n",
        "\n",
        "Another issue is that we have some words that are so common that do not give much information (think of words like \"is\", \"the\", etc.). In order to reduce the effect of those words, one can use the *tf-idf* method, where on top of normalizing based on the length of the documents (*tf*), we also downscale weights for words that are presented in many documents (*idf* stands for inverse document frequency)\n",
        "\n",
        "If you are interested to know more about tf-idf, feel free to check out the wikipedia page. \n",
        "\n",
        "For this assignment, we will use *tf* and also *tf-idf* noramalization.\n",
        "\n",
        "The below application of ***TfidfTransformer*** is showed when idf is turned off. Evidently, we don't observe any changes in our feature dimension after performing **tf-idf** step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "402y-_ZUleyh"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidfconverter = TfidfTransformer(use_idf=False)\n",
        "X_tfidf_train = tfidfconverter.fit_transform(X_counts_train).toarray()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTGDzuZzmhPo"
      },
      "source": [
        "# Document classification\n",
        "K-nearest neighbours (KNNs) are one of the most common classifiers in practices. Here we train an KNN classifier on the transformed features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8GzFxh-bVtc",
        "outputId": "4ca20295-7cd4-4987-d3c0-ddbd9675b997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.6425\n"
          ]
        }
      ],
      "source": [
        "\n",
        "classifier1=KNeighborsClassifier(n_neighbors=2)\n",
        "classifier1.fit(X_tfidf_train, labels_train)\n",
        "X_counts_test = count_vect.transform(np.array(pre_processed_reviews_test))\n",
        "X_tfidf_test = tfidfconverter.transform(X_counts_test).toarray()\n",
        "predicted = classifier1.predict(X_tfidf_test)\n",
        "print('Accuracy:{}'.format(np.mean(predicted == labels_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl3bN934bVtd"
      },
      "source": [
        "# Pipeline\n",
        "We can do three tasks (vectorizer,transformer,classifier) using pipeline procedure.\n",
        "We can create a \"pipeline\" for performing a sequence of steps, namely first extracting the words and creating vectors, then using tf or tf-idf, and then training the classifier. This helps to make our code cleaner (and allows for more code optimization, etc.) We utilize a pipeline to do vectorizer -> transformer -> classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ASd6Z5bVtd",
        "outputId": "ade97b24-1673-4b51-bd5b-71f9e811763d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.6425\n"
          ]
        }
      ],
      "source": [
        "text_classifier1 = Pipeline([\n",
        "      ('vect', CountVectorizer()),\n",
        "      ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "      ('classifier1', KNeighborsClassifier(n_neighbors=2)),\n",
        "  ])\n",
        "text_classifier1.fit(pre_processed_reviews_train, labels_train)\n",
        "docs_test = pre_processed_reviews_test\n",
        "predicted = text_classifier1.predict(docs_test)\n",
        "print('Accuracy:{}'.format(np.mean(predicted ==  labels_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVQP_wvHbVtd"
      },
      "source": [
        "# <font color=\"red\">Task 1 (15 points) </font>\n",
        "\n",
        "## Logistic Regression Classifier:\n",
        "\n",
        "In this part, we will test Logistic Regression(LR) with three distinct penalties: 'none', 'l1' and 'l2'. Report test accuracies and justify the result. The solver can be set to 'saga' to support both types of penalties. The details about LR will be found on \n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "\n",
        "#sklearn.linear_model.LogisticRegression\n",
        "\n",
        "Please use the following settings:\n",
        "\n",
        "count_vect = CountVectorizer(max_features=100)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfQbERDNbVtd",
        "outputId": "37328e07-4cb6-4d90-dedf-27608a951f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy penalty \"none\" :0.7175\n",
            "Accuracy penalty \"l1\" :0.7\n",
            "Accuracy penalty \"l2\" :0.69\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "# In this task we see that the \"none\" penalty has the highest accuracy\n",
        "# l1 penalizes the sum of absolute values of the weights whereas l2 peanlizes the sum of squares of the weights \n",
        "# Tfidf goal is to is to scale down the impact of the tokens\n",
        "\n",
        "# L1 and L2 are regularizations that can be used to address an overfitting issue\n",
        "\n",
        "# The reason in Task1, the penalty 'none' has the highest accuracy is because a peanlty tries to reduce overfitting. So no peantly being added in this task, is ideal as we are not looking\n",
        "# weights of data or anythig like that. Here an overfitting would be good.\n",
        "# Overfitting gives high accuracy when all we have is the training data, however, doesn't do well with a test set or some other data.\n",
        "\n",
        "penalties = [\"none\", \"l1\", \"l2\"]\n",
        "\n",
        "for pen in penalties:\n",
        "  text_classifier1 = Pipeline([\n",
        "      ('vect', CountVectorizer(max_features = 100)),\n",
        "      ('tfidf', TfidfTransformer(use_idf=False)),\n",
        "      ('classifier1', LogisticRegression(penalty = pen, solver = 'saga', max_iter=1000)),\n",
        "  ])\n",
        "  text_classifier1.fit(pre_processed_reviews_train, labels_train)\n",
        "  docs_test = pre_processed_reviews_test\n",
        "  predicted = text_classifier1.predict(docs_test)\n",
        "  print('Accuracy penalty \"{}\" :{}'.format(pen,np.mean(predicted ==  labels_test))) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA5lkw0AbVte"
      },
      "source": [
        "# <font color=\"red\">Task 2 (5 points) </font>\n",
        " \n",
        "## idf importance:\n",
        "  \n",
        "How would the results of Task 1 change if we turn on TfidfTransformer(use_idf=True)?\n",
        "    \n",
        "Report the results on the test set and justify them.\n",
        "Please use the following settings:\n",
        "        \n",
        "count_vect = CountVectorizer(max_features=1500)\n",
        "\n",
        "Tfidfconverter = TfidfTransformer(use_idf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnY8zbs8bVte",
        "outputId": "36cce6e1-7da2-492a-8152-158589c356b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy penalty \"none\" :0.79\n",
            "Accuracy penalty \"l1\" :0.805\n",
            "Accuracy penalty \"l2\" :0.8\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "#In this task we see that either penalties l1 and l2 have the same accuracy or l1 is larger then l2 (in both cases none has the lowest)\n",
        "#Tf-idf's goal is scale down the ipmact of tokens that occur very frequently. It takes a string and quantifies the importance of the string\n",
        "#l1 shrinks coeefficients to zero whereas l2 shrinks coefficients evenly. \n",
        "\n",
        "#The reason which the 'none' penalty has the lowest accuracy is because when TfidTransformer is set to true, as we are now considering the weight of the data, the penalty does nothing to \n",
        "#change any of the data points weight. As explained earlier, l1 shrinks the coefficients to zero and l2 shrinks coefficients evenly. The reason l1 has a higher accuracy then l2 is because \n",
        "#l1 creates a larger difference between weights of different strings. Shrinking it to 0 compared to shrinking them evenly like l2 allows for the algorithm to see who is more accurate. However,\n",
        "#the difference of accuracy is not a very large, amount, sometimes so little the output states they are equal\n",
        "penalties = [\"none\", \"l1\", \"l2\"]\n",
        "\n",
        "\n",
        "for pen in penalties:\n",
        "  text_classifier1 = Pipeline([\n",
        "      ('vect', CountVectorizer(max_features = 1500)),\n",
        "      ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "      ('classifier1', LogisticRegression(penalty = pen, solver = 'saga', max_iter=1600)),\n",
        "  ])\n",
        "  text_classifier1.fit(pre_processed_reviews_train, labels_train)\n",
        "  docs_test = pre_processed_reviews_test\n",
        "  predicted = text_classifier1.predict(docs_test)\n",
        "  print('Accuracy penalty \"{}\" :{}'.format(pen,np.mean(predicted ==  labels_test))) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryAWDeFonFWm",
        "outputId": "053a1f44-bdd4-4cf2-99f2-0eb01f92c869"
      },
      "source": [
        " # <font color=\"red\">Task 3 (10 points) </font>\n",
        "\n",
        "## Importance of maximum feature size:\n",
        "\n",
        "Examine the vocabulary size, max feature choices for CountVectorizer: 100, 500, 1000, 1500, and 2000. \n",
        "Which size of vocabulary yields the greatest results on the test samples? Justify your answer. \n",
        "Please use the following settings:\n",
        "\n",
        "tfidfconverter = TfidfTransformer(use_idf=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xf3fSX2fpPb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3653d3e6-ef34-4f8e-947e-bee47011e04c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Count Vector Size = \"100\"\n",
            "Accuracy penalty \"none\": 0.715\n",
            "Accuracy penalty \"l1\": 0.71\n",
            "Accuracy penalty \"l2\": 0.7075\n",
            "\n",
            "Count Vector Size = \"500\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy penalty \"none\": 0.74\n",
            "Accuracy penalty \"l1\": 0.795\n",
            "Accuracy penalty \"l2\": 0.7775\n",
            "\n",
            "Count Vector Size = \"1000\"\n",
            "Accuracy penalty \"none\": 0.775\n",
            "Accuracy penalty \"l1\": 0.8025\n",
            "Accuracy penalty \"l2\": 0.7975\n",
            "\n",
            "Count Vector Size = \"1500\"\n",
            "Accuracy penalty \"none\": 0.7925\n",
            "Accuracy penalty \"l1\": 0.8025\n",
            "Accuracy penalty \"l2\": 0.8\n",
            "\n",
            "Count Vector Size = \"2000\"\n",
            "Accuracy penalty \"none\": 0.8325\n",
            "Accuracy penalty \"l1\": 0.8025\n",
            "Accuracy penalty \"l2\": 0.8025\n"
          ]
        }
      ],
      "source": [
        "# write your code here\n",
        "#The greateer the countVectorSize, the higher the accuracy, meaning, that 2000 countVectorSize yields teh greatest results on the test samples\n",
        "penalties = [\"none\", \"l1\", \"l2\"]\n",
        "countVectorSize = [100, 500, 1000, 1500, 2000]\n",
        "\n",
        "for count in countVectorSize:\n",
        "  print('\\nCount Vector Size = \"{}\"'.format(count))\n",
        "  for pen in penalties:\n",
        "    max = 2000\n",
        "    \n",
        "    text_classifier1 = Pipeline([\n",
        "      ('vect', CountVectorizer(max_features = count)),\n",
        "      ('tfidf', TfidfTransformer(use_idf=True)),\n",
        "      ('classifier1', LogisticRegression(penalty = pen, solver = 'saga', max_iter=max)),\n",
        "    ])\n",
        "    text_classifier1.fit(pre_processed_reviews_train, labels_train)\n",
        "    docs_test = pre_processed_reviews_test\n",
        "    predicted = text_classifier1.predict(docs_test)\n",
        "    print('Accuracy penalty \"{}\": {}'.format(pen,np.mean(predicted ==  labels_test))) \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSlTq32lEvlh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}